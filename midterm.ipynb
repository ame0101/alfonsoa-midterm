{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pCRpk0pT1AF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import nltk\n",
        "from pandarallel import pandarallel\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "pandarallel.initialize(progress_bar=True)\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "\n",
        "train_data_full = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "train_data = train_data_full.sample(frac=0.5, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "if 'Text' not in train_data.columns:\n",
        "    train_data['Text'] = ''\n",
        "train_data['Text'] = train_data['Text'].fillna('').astype(str)\n",
        "\n",
        "\n",
        "def extract_features(df, is_test=False, product_avg=None, user_avg=None):\n",
        "    if 'Text' not in df.columns:\n",
        "        df['Text'] = ''\n",
        "    df['Text'] = df['Text'].fillna('').astype(str)\n",
        "\n",
        "\n",
        "    def sentiment_scores(text):\n",
        "        scores = analyzer.polarity_scores(text)\n",
        "        return pd.Series({\n",
        "            'Sentiment_Neg': scores['neg'],\n",
        "            'Sentiment_Neu': scores['neu'],\n",
        "            'Sentiment_Pos': scores['pos'],\n",
        "            'Sentiment_Compound': scores['compound']\n",
        "        })\n",
        "    sentiment_df = df['Text'].parallel_apply(sentiment_scores)\n",
        "    df = pd.concat([df.reset_index(drop=True), sentiment_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "\n",
        "    df['TextLength'] = df['Text'].str.len()\n",
        "    df['ExclamationCount'] = df['Text'].str.count(\"!\")\n",
        "    df['QuestionCount'] = df['Text'].str.count(r\"\\?\")\n",
        "    df['CapitalRatio'] = df['Text'].str.count(r'[A-Z]') / (df['TextLength'] + 1)\n",
        "    df['UppercaseWords'] = df['Text'].str.count(r'\\b[A-Z]{2,}\\b')\n",
        "\n",
        "\n",
        "    df['SentimentMapped'] = ((df['Sentiment_Compound'] + 1) * 2) + 1\n",
        "    df['SentimentLevel'] = df['Sentiment_Compound'].apply(lambda x: 1 if x <= -0.6 else 2 if x <= -0.2 else 3 if x <= 0.2 else 4 if x <= 0.6 else 5)\n",
        "\n",
        "\n",
        "    if 'HelpfulnessNumerator' in df.columns and 'HelpfulnessDenominator' in df.columns:\n",
        "        df['HelpfulnessRatio'] = df['HelpfulnessNumerator'] / (df['HelpfulnessDenominator'] + 1)\n",
        "    else:\n",
        "        df['HelpfulnessRatio'] = 0.0\n",
        "\n",
        "\n",
        "    df['Sentiment_Helpfulness'] = df['Sentiment_Compound'] * df['HelpfulnessRatio']\n",
        "    df['Sentiment_TextLength'] = df['Sentiment_Compound'] * df['TextLength']\n",
        "\n",
        "\n",
        "    if not is_test and 'Score' in df.columns:\n",
        "        df['Score'] = pd.to_numeric(df['Score'], errors='coerce')\n",
        "        df_non_null = df.dropna(subset=['Score'])\n",
        "\n",
        "        if 'ProductId' in df.columns:\n",
        "            product_avg = df_non_null.groupby('ProductId')['Score'].mean().reset_index().rename(columns={'Score': 'ProductAvgScore'})\n",
        "            df = df.merge(product_avg, on='ProductId', how='left')\n",
        "        else:\n",
        "            df['ProductAvgScore'] = df['Score'].mean()\n",
        "\n",
        "        if 'UserId' in df.columns:\n",
        "            user_avg = df_non_null.groupby('UserId')['Score'].mean().reset_index().rename(columns={'Score': 'UserAvgScore'})\n",
        "            df = df.merge(user_avg, on='UserId', how='left')\n",
        "        else:\n",
        "            df['UserAvgScore'] = df['Score'].mean()\n",
        "    else:\n",
        "        if 'ProductId' in df.columns and product_avg is not None:\n",
        "            df = df.merge(product_avg, on='ProductId', how='left')\n",
        "        else:\n",
        "            df['ProductAvgScore'] = train_data['Score'].mean()\n",
        "\n",
        "        if 'UserId' in df.columns and user_avg is not None:\n",
        "            df = df.merge(user_avg, on='UserId', how='left')\n",
        "        else:\n",
        "            df['UserAvgScore'] = train_data['Score'].mean()\n",
        "\n",
        "\n",
        "    df.fillna({\n",
        "        'SentimentMapped': 3, 'SentimentLevel': 3, 'HelpfulnessRatio': 0.0,\n",
        "        'TextLength': 0, 'ExclamationCount': 0, 'QuestionCount': 0,\n",
        "        'CapitalRatio': 0.0, 'UppercaseWords': 0, 'Sentiment_Helpfulness': 0.0,\n",
        "        'Sentiment_TextLength': 0.0, 'ProductAvgScore': train_data['Score'].mean(),\n",
        "        'UserAvgScore': train_data['Score'].mean(), 'Sentiment_Neg': 0.0,\n",
        "        'Sentiment_Neu': 0.0, 'Sentiment_Pos': 0.0, 'Sentiment_Compound': 0.0\n",
        "    }, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "train_data = extract_features(train_data)\n",
        "train_data = train_data.dropna(subset=['Score'])\n",
        "train_data['Score'] = train_data['Score'].astype(int)\n",
        "\n",
        "\n",
        "product_avg = train_data.groupby('ProductId')['Score'].mean().reset_index().rename(columns={'Score': 'ProductAvgScore'})\n",
        "user_avg = train_data.groupby('UserId')['Score'].mean().reset_index().rename(columns={'Score': 'UserAvgScore'})\n",
        "\n",
        "\n",
        "feature_columns = [\n",
        "    'SentimentMapped', 'SentimentLevel', 'HelpfulnessRatio', 'TextLength',\n",
        "    'ExclamationCount', 'QuestionCount', 'CapitalRatio', 'UppercaseWords',\n",
        "    'Sentiment_Helpfulness', 'Sentiment_TextLength', 'ProductAvgScore',\n",
        "    'UserAvgScore', 'Sentiment_Neg', 'Sentiment_Neu', 'Sentiment_Pos', 'Sentiment_Compound'\n",
        "]\n",
        "X_numeric = train_data[feature_columns]\n",
        "y = train_data['Score']\n",
        "\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X_text_tfidf = tfidf_vectorizer.fit_transform(train_data['Text'])\n",
        "\n",
        "\n",
        "X_numeric_scaled = StandardScaler().fit_transform(X_numeric)\n",
        "X_combined = hstack([csr_matrix(X_numeric_scaled), X_text_tfidf])\n",
        "\n",
        "\n",
        "param_grid = {'C': [0.1, 0.5, 1.0], 'solver': ['newton-cg', 'lbfgs'], 'max_iter': [1000, 2000]}\n",
        "log_reg = LogisticRegression(multi_class='multinomial', n_jobs=-1)\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "\n",
        "\n",
        "grid_search.fit(X_combined, y)\n",
        "best_params = grid_search.best_params_\n",
        "log_reg_model = LogisticRegression(max_iter=best_params['max_iter'], solver=best_params['solver'], C=best_params['C'], multi_class='multinomial', n_jobs=-1)\n",
        "log_reg_model.fit(X_combined, y)\n",
        "\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(log_reg_model, X_combined, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"Cross-validation accuracy: {cv_scores.mean():.4f}\")\n",
        "\n",
        "\n",
        "train_data_full_unique = train_data_full.drop_duplicates(subset='Id')\n",
        "test_data = test_data.merge(train_data_full_unique[['Id', 'Text', 'ProductId', 'UserId', 'HelpfulnessNumerator', 'HelpfulnessDenominator']], on='Id', how='left')\n",
        "test_data['Text'] = test_data['Text'].fillna('')\n",
        "\n",
        "\n",
        "test_data = extract_features(test_data, is_test=True, product_avg=product_avg, user_avg=user_avg)\n",
        "\n",
        "\n",
        "X_test_numeric = test_data[feature_columns]\n",
        "X_test_numeric_scaled = StandardScaler().fit_transform(X_test_numeric)\n",
        "X_test_text_tfidf = tfidf_vectorizer.transform(test_data['Text'])\n",
        "X_test_combined = hstack([csr_matrix(X_test_numeric_scaled), X_test_text_tfidf])\n",
        "\n",
        "\n",
        "test_data['Score'] = log_reg_model.predict(X_test_combined)\n",
        "test_data['Score'] = test_data['Score'].round().clip(1, 5).astype(int)\n",
        "\n",
        "\n",
        "test_data[['Id', 'Score']].to_csv('submission.csv', index=False)\n",
        "print(\"Score prediction complete; file saved as 'submission.csv'.\")\n"
      ]
    }
  ]
}